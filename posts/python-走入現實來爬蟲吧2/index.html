<!doctype html><html lang=en><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge,chrome=1"><title>Python 走入現實：來爬蟲吧(2) - Jimmy's Code</title>
<meta name=renderer content="webkit"><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1"><meta http-equiv=Cache-Control content="no-transform"><meta http-equiv=Cache-Control content="no-siteapp"><meta name=theme-color content="#f8f5ec"><meta name=msapplication-navbutton-color content="#f8f5ec"><meta name=apple-mobile-web-app-capable content="yes"><meta name=apple-mobile-web-app-status-bar-style content="#f8f5ec"><meta name=author content="r567tw"><meta name=description content="前一天我們談到如何使用Python發出類似瀏覽器的request，把所要的HTML+CSS+JS都給他抓過來。但是如果只是這樣那爬蟲又有什麼"><meta name=keywords content="r567tw,Coding,Programming,Life,Blog"><meta name=generator content="Hugo 0.123.7 with theme even"><link rel=canonical href=https://r567tw.github.io/blog-site/posts/python-%E8%B5%B0%E5%85%A5%E7%8F%BE%E5%AF%A6%E4%BE%86%E7%88%AC%E8%9F%B2%E5%90%A72/><link rel=apple-touch-icon sizes=180x180 href=/blog-site/apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=/blog-site/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/blog-site/favicon-16x16.png><link rel=manifest href=/blog-site/manifest.json><link rel=mask-icon href=/blog-site/safari-pinned-tab.svg color=#5bbad5><link href=/blog-site/sass/main.min.75e9b34406eb06bc8d3f31239cc5f7fc476beabf57adb3ef0632c75958a8a097.css rel=stylesheet><link rel=stylesheet href=/css/custom.css><meta property="og:title" content="Python 走入現實：來爬蟲吧(2)"><meta property="og:description" content="前一天我們談到如何使用Python發出類似瀏覽器的request，把所要的HTML+CSS+JS都給他抓過來。但是如果只是這樣那爬蟲又有什麼"><meta property="og:type" content="article"><meta property="og:url" content="https://r567tw.github.io/blog-site/posts/python-%E8%B5%B0%E5%85%A5%E7%8F%BE%E5%AF%A6%E4%BE%86%E7%88%AC%E8%9F%B2%E5%90%A72/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2018-10-17T14:02:02+00:00"><meta property="article:modified_time" content="2018-10-17T14:02:02+00:00"><meta itemprop=name content="Python 走入現實：來爬蟲吧(2)"><meta itemprop=description content="前一天我們談到如何使用Python發出類似瀏覽器的request，把所要的HTML+CSS+JS都給他抓過來。但是如果只是這樣那爬蟲又有什麼"><meta itemprop=datePublished content="2018-10-17T14:02:02+00:00"><meta itemprop=dateModified content="2018-10-17T14:02:02+00:00"><meta itemprop=wordCount content="1270"><meta itemprop=keywords content="python,"><meta name=twitter:card content="summary"><meta name=twitter:title content="Python 走入現實：來爬蟲吧(2)"><meta name=twitter:description content="前一天我們談到如何使用Python發出類似瀏覽器的request，把所要的HTML+CSS+JS都給他抓過來。但是如果只是這樣那爬蟲又有什麼"><!--[if lte IE 9]><script src=https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js></script><![endif]--><!--[if lt IE 9]><script src=https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js></script><script src=https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js></script><![endif]--></head><body><div id=mobile-navbar class=mobile-navbar><div class=mobile-header-logo><a href=/ class=logo>Jimmy's Code</a></div><div class=mobile-navbar-icon><span></span>
<span></span>
<span></span></div></div><nav id=mobile-menu class="mobile-menu slideout-menu"><ul class=mobile-menu-list><a href=/blog-site/about/><li class=mobile-menu-item>About</li></a><a href=/blog-site/categories/><li class=mobile-menu-item>Categories</li></a><a href=/blog-site/posts/><li class=mobile-menu-item>Archives</li></a><a href=https://jimmynotes.netlify.app/><li class=mobile-menu-item>Notes</li></a><a href=/blog-site/search><li class=mobile-menu-item>Search</li></a></ul></nav><div class=container id=mobile-panel><header id=header class=header><div class=logo-wrapper><a href=/ class=logo>Jimmy's Code</a></div><nav class=site-navbar><ul id=menu class=menu><li class=menu-item><a class=menu-item-link href=/blog-site/about/>About</a></li><li class=menu-item><a class=menu-item-link href=/blog-site/categories/>Categories</a></li><li class=menu-item><a class=menu-item-link href=/blog-site/posts/>Archives</a></li><li class=menu-item><a class=menu-item-link href=https://jimmynotes.netlify.app/>Notes</a></li><li class=menu-item><a class=menu-item-link href=/blog-site/search>Search</a></li></ul></nav></header><main id=main class=main><div class=content-wrapper><div id=content class=content><article class=post><header class=post-header><h1 class=post-title>Python 走入現實：來爬蟲吧(2)</h1><div class=post-meta><span class=post-time>2018-10-17</span><div class=post-category><a href=/blog-site/categories/ithome/>ithome</a></div></div></header><div class=post-toc id=post-toc><h2 class=post-toc-title>Contents</h2><div class=post-toc-content><nav id=TableOfContents><ul><li><a href=#beautifulsoup>BeautifulSoup</a></li></ul></nav></div></div><div class=post-content><p>前一天我們談到如何使用Python發出類似瀏覽器的request，把所要的HTML+CSS+JS都給他抓過來。但是如果只是這樣那爬蟲又有什麼多厲害呢？ 爬蟲的厲害之處就是能把抓回來的東西，拿出來好好的分析，<em><strong>藉此獲得我們想要的資訊或者有用的資訊</strong></em></p><p>因此，讓我接下來為他介紹收到request之後的事情吧！</p><h1 id=beautifulsoup>BeautifulSoup</h1><p>其實Python有許多的爬蟲套件，我之前個人下班在玩的時候都是用這個套件，當然也有其他可以爬的套件。這裏我介紹某位youtuber的資源：<a href="https://www.youtube.com/watch?v=T2xNeWutlcA">https://www.youtube.com/watch?v=T2xNeWutlcA</a></p><p>厲害吧！他居然用Python爬蟲去抓成人影片！呵呵 不過他用的是另外一種module 叫做pyquery</p><p>好啦，確定你有安裝好beautifulSoup之後就來開始吧這裡就不抓成人影片了，我們先開始抓取‘文字內容’，明天再來講我們怎麼抓取非文字內容的資料。我們來抓youtube今天熱門影片的標題們XD</p><p>大家都知道：youtube的熱門影片網址是：<a href=https://www.youtube.com/feed/trending>https://www.youtube.com/feed/trending</a></p><div class=highlight><div class=chroma><table class=lntable><tr><td class=lntd><pre tabindex=0 class=chroma><code><span class=lnt> 1
</span><span class=lnt> 2
</span><span class=lnt> 3
</span><span class=lnt> 4
</span><span class=lnt> 5
</span><span class=lnt> 6
</span><span class=lnt> 7
</span><span class=lnt> 8
</span><span class=lnt> 9
</span><span class=lnt>10
</span><span class=lnt>11
</span><span class=lnt>12
</span><span class=lnt>13
</span><span class=lnt>14
</span><span class=lnt>15
</span><span class=lnt>16
</span><span class=lnt>17
</span><span class=lnt>18
</span><span class=lnt>19
</span><span class=lnt>20
</span><span class=lnt>21
</span><span class=lnt>22
</span><span class=lnt>23
</span><span class=lnt>24
</span></code></pre></td><td class=lntd><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>requests</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>bs4</span> <span class=kn>import</span> <span class=n>BeautifulSoup</span><span class=p>;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>content</span><span class=o>=</span><span class=n>request</span><span class=o>.</span><span class=n>content</span>
</span></span><span class=line><span class=cl><span class=n>soup</span><span class=o>=</span><span class=n>BeautifulSoup</span><span class=p>(</span><span class=n>content</span><span class=p>,</span><span class=s2>&#34;html.parser&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>container</span> <span class=o>=</span> <span class=n>soup</span><span class=o>.</span><span class=n>select</span><span class=p>(</span><span class=s2>&#34;h3 a&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># print(type(container))</span>
</span></span><span class=line><span class=cl><span class=c1># print(container)</span>
</span></span><span class=line><span class=cl><span class=c1># 接下來只是寫入result.txt檔案的事情</span>
</span></span><span class=line><span class=cl><span class=n>file</span> <span class=o>=</span> <span class=nb>open</span><span class=p>(</span><span class=s1>&#39;result.text&#39;</span><span class=p>,</span><span class=s1>&#39;w&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>item</span> <span class=ow>in</span> <span class=n>container</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=n>item</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=c1>#print(type(item))</span>
</span></span><span class=line><span class=cl>        <span class=n>value</span> <span class=o>=</span> <span class=n>item</span><span class=o>.</span><span class=n>get_text</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=n>value</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>file</span><span class=o>.</span><span class=n>write</span><span class=p>(</span><span class=n>value</span><span class=o>+</span><span class=s1>&#39;</span><span class=se>\n</span><span class=s1>&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=c1>#break #這裡也提一個起手式的遺珠之憾，就是你可以用continue和break來處理 迴圈敘述，這裏為了我之前debug方便，使用break來讓我先只看一個的結果。</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>file</span><span class=o>.</span><span class=n>close</span><span class=p>()</span>
</span></span></code></pre></td></tr></table></div></div><p>用範例講解：首先先把兩個module beautifulsoup ＆request引入接下來你會看到我使用request.get 取得熱門影片的youtube網頁的內容。再來你就用<code>soup=BeautifulSoup(content,"html.parser")</code>把content 丟入beautifulSoup解析，後面參數記得加上‘html.parser’</p><p>然後回去用瀏覽器打開<a href=https://www.youtube.com/feed/trending/>https://www.youtube.com/feed/trending/</a> 這個網頁，可能希望你會有一些基礎的html+css基礎，總之你可以仔細看看每個標題的地方，上面都會有h3 以及我們最想要的標題文字正好都被包在a這裡面。</p><p>所以我們可以使用<code>container = soup.select("h3 a")</code>來把所有的標題提出來。接下來只是寫入result.txt檔案的事情了</p><ol><li>你可以先<code>print(container)</code>和<code>print(type(container))</code> : 你會發現他是<code>&lt;class 'list'></code> ，所以你知道了吧！他就是個 list，所以後面我用迴圈把他一一提取出來。2.進入迴圈後如果你還是很好奇，可以用print(type(item))看看：他是<code>&lt;class 'bs4.element.Tag'></code>，所以後面我可以用get_text()這個方法取出他的標題文字。</li></ol><p>關於beautifulsoup還有很多可以在教學或更多運用的，這裏我附上我debug參考的一些網址</p><p>更多BeautifulSoup教學： <a href=https://www.dataquest.io/blog/web-scraping-tutorial-Python/>https://www.dataquest.io/blog/web-scraping-tutorial-Python/</a></p><p>明天我將試看看爬多媒體資源看看！敬請期待！</p></div><footer class=post-footer><div class=post-tags><a href=/blog-site/tags/python/>python</a></div><nav class=post-nav><a class=prev href=/blog-site/posts/python-%E8%B5%B0%E5%85%A5%E7%8F%BE%E5%AF%A6%E6%AD%A3%E8%A6%8F%E8%A1%A8%E9%81%94%E5%BC%8F/><i class="iconfont icon-left"></i>
<span class="prev-text nav-default">Python 走入現實：正規表達式</span>
<span class="prev-text nav-mobile">Prev</span>
</a><a class=next href=/blog-site/posts/python-%E8%B5%B0%E5%85%A5%E7%8F%BE%E5%AF%A6%E4%BE%86%E7%88%AC%E8%9F%B2%E5%90%A71/><span class="next-text nav-default">Python 走入現實：來爬蟲吧(1)</span>
<span class="next-text nav-mobile">Next</span>
<i class="iconfont icon-right"></i></a></nav></footer></article></div></div></main><footer id=footer class=footer><div class=social-links></div><div class=copyright><span class=power-by>Powered by <a class=hexo-link href=https://gohugo.io>Hugo</a>
</span><span class=division>|</span>
<span class=theme-info>Theme -
<a class=theme-link href=https://github.com/olOwOlo/hugo-theme-even>Even</a>
</span><span class=copyright-year>&copy;
2017 -
2024<span class=heart><i class="iconfont icon-heart"></i></span>
<span>r567tw</span></span></div></footer><div class=back-to-top id=back-to-top><i class="iconfont icon-up"></i></div></div><script src=https://cdn.jsdelivr.net/npm/jquery@3.2.1/dist/jquery.min.js integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4=" crossorigin=anonymous></script><script src=https://cdn.jsdelivr.net/npm/slideout@1.0.1/dist/slideout.min.js integrity="sha256-t+zJ/g8/KXIJMjSVQdnibt4dlaDxc9zXr/9oNPeWqdg=" crossorigin=anonymous></script><script type=text/javascript src=/blog-site/js/main.min.4ae89da218555efa0e7093a20b92017d2e1202b66fff9fc2edf4cb8d44b44c6e.js></script><script async src="https://www.googletagmanager.com/gtag/js?id=G-7PPECL3Q0"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-7PPECL3Q0")</script></body></html>