<!doctype html><html lang=zh-tw data-mode=dark><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><title>Python 走入現實：來爬蟲吧(2) - Jimmy 's Code</title><link rel=apple-touch-icon href=https://jimmycode.tw/images/favicons/apple-touch-icon.png sizes=180x180><link rel=icon href=https://jimmycode.tw/images/favicons/favicon-32x32.png sizes=32x32 type=image/png><link rel=icon href=https://jimmycode.tw/images/favicons/favicon-16x16.png sizes=16x16 type=image/png><link rel=manifest href=https://jimmycode.tw/images/favicons/manifest.json><link rel=icon href=https://jimmycode.tw/images/favicons/favicon.ico><meta name=keywords content><meta name=description content><meta itemprop=name content="Python 走入現實：來爬蟲吧(2)"><meta itemprop=description content="前一天我們談到如何使用Python發出類似瀏覽器的request，把所要的HTML+CSS+JS都給他抓過來。但是如果只是這樣那爬蟲又有什麼多厲害呢？ 爬蟲的厲害之處就是能把抓回來的東西，拿出來好好的分析，藉此獲得我們想要的資訊或者有用的資訊
因此，讓我接下來為他介紹收到request之後的事情吧！
BeautifulSoup 其實Python有許多的爬蟲套件，我之前個人下班在玩的時候都是用這個套件，當然也有其他可以爬的套件。這裏我介紹某位youtuber的資源：https://www.youtube.com/watch?v=T2xNeWutlcA
厲害吧！他居然用Python爬蟲去抓成人影片！呵呵 不過他用的是另外一種module 叫做pyquery
好啦，確定你有安裝好beautifulSoup之後就來開始吧這裡就不抓成人影片了，我們先開始抓取‘文字內容’，明天再來講我們怎麼抓取非文字內容的資料。我們來抓youtube今天熱門影片的標題們XD
大家都知道：youtube的熱門影片網址是：https://www.youtube.com/feed/trending
1import requests; 2from bs4 import BeautifulSoup; 3 4url=&#34;https://www.youtube.com/feed/trending/&#34; 5 6request=requests.get(url) 7content=request.content 8soup=BeautifulSoup(content,&#34;html.parser&#34;) 9 10container = soup.select(&#34;h3 a&#34;) 11 12# print(type(container)) 13# print(container) 14# 接下來只是寫入result.txt檔案的事情 15file = open('result.text','w') 16 17for item in container: 18 if item: 19 #print(type(item)) 20 value = item.get_text() 21 print(value) 22 file.write(value+'\n') 23 #break #這裡也提一個起手式的遺珠之憾，就是你可以用continue和break來處理 迴圈敘述，這裏為了我之前debug方便，使用break來讓我先只看一個的結果。 24 25 26file.close() 用範例講解：首先先把兩個module beautifulsoup ＆request引入接下來你會看到我使用request.get 取得熱門影片的youtube網頁的內容。再來你就用soup=BeautifulSoup(content,&#34;html.parser&#34;)把content 丟入beautifulSoup解析，後面參數記得加上‘html.parser’
然後回去用瀏覽器打開https://www.youtube.com/feed/trending/ 這個網頁，可能希望你會有一些基礎的html+css基礎，總之你可以仔細看看每個標題的地方，上面都會有h3 以及我們最想要的標題文字正好都被包在a這裡面。"><meta itemprop=datePublished content="2018-10-17T14:02:02+00:00"><meta itemprop=dateModified content="2018-10-17T14:02:02+00:00"><meta itemprop=wordCount content="85"><meta itemprop=keywords content="python,"><meta property="og:title" content="Python 走入現實：來爬蟲吧(2)"><meta property="og:description" content="前一天我們談到如何使用Python發出類似瀏覽器的request，把所要的HTML+CSS+JS都給他抓過來。但是如果只是這樣那爬蟲又有什麼多厲害呢？ 爬蟲的厲害之處就是能把抓回來的東西，拿出來好好的分析，藉此獲得我們想要的資訊或者有用的資訊
因此，讓我接下來為他介紹收到request之後的事情吧！
BeautifulSoup 其實Python有許多的爬蟲套件，我之前個人下班在玩的時候都是用這個套件，當然也有其他可以爬的套件。這裏我介紹某位youtuber的資源：https://www.youtube.com/watch?v=T2xNeWutlcA
厲害吧！他居然用Python爬蟲去抓成人影片！呵呵 不過他用的是另外一種module 叫做pyquery
好啦，確定你有安裝好beautifulSoup之後就來開始吧這裡就不抓成人影片了，我們先開始抓取‘文字內容’，明天再來講我們怎麼抓取非文字內容的資料。我們來抓youtube今天熱門影片的標題們XD
大家都知道：youtube的熱門影片網址是：https://www.youtube.com/feed/trending
1import requests; 2from bs4 import BeautifulSoup; 3 4url=&#34;https://www.youtube.com/feed/trending/&#34; 5 6request=requests.get(url) 7content=request.content 8soup=BeautifulSoup(content,&#34;html.parser&#34;) 9 10container = soup.select(&#34;h3 a&#34;) 11 12# print(type(container)) 13# print(container) 14# 接下來只是寫入result.txt檔案的事情 15file = open('result.text','w') 16 17for item in container: 18 if item: 19 #print(type(item)) 20 value = item.get_text() 21 print(value) 22 file.write(value+'\n') 23 #break #這裡也提一個起手式的遺珠之憾，就是你可以用continue和break來處理 迴圈敘述，這裏為了我之前debug方便，使用break來讓我先只看一個的結果。 24 25 26file.close() 用範例講解：首先先把兩個module beautifulsoup ＆request引入接下來你會看到我使用request.get 取得熱門影片的youtube網頁的內容。再來你就用soup=BeautifulSoup(content,&#34;html.parser&#34;)把content 丟入beautifulSoup解析，後面參數記得加上‘html.parser’
然後回去用瀏覽器打開https://www.youtube.com/feed/trending/ 這個網頁，可能希望你會有一些基礎的html+css基礎，總之你可以仔細看看每個標題的地方，上面都會有h3 以及我們最想要的標題文字正好都被包在a這裡面。"><meta property="og:type" content="article"><meta property="og:url" content="https://jimmycode.tw/posts/Python-%E8%B5%B0%E5%85%A5%E7%8F%BE%E5%AF%A6%EF%BC%9A%E4%BE%86%E7%88%AC%E8%9F%B2%E5%90%A72/"><meta property="article:section" content="posts"><meta property="article:published_time" content="2018-10-17T14:02:02+00:00"><meta property="article:modified_time" content="2018-10-17T14:02:02+00:00"><meta property="og:see_also" content="https://jimmycode.tw/posts/Python-%E9%90%B5%E4%BA%BA%E8%B3%BD%EF%BC%9A%E9%81%BA%E7%8F%A0%E4%B9%8B%E6%86%BE/"><meta property="og:see_also" content="https://jimmycode.tw/posts/Python-%E8%B3%87%E6%96%99%E7%A7%91%E5%AD%B8%EF%BC%9Apandas/"><meta property="og:see_also" content="https://jimmycode.tw/posts/Python-%E7%B6%B2%E9%A0%81%EF%BC%9Aflask/"><meta property="og:see_also" content="https://jimmycode.tw/posts/Python-%E7%B6%B2%E9%A0%81%EF%BC%9Adjango-%E4%BE%86%E5%81%9A%E4%B8%80%E5%80%8B%E9%83%A8%E8%90%BD%E6%A0%BC2/"><meta property="og:see_also" content="https://jimmycode.tw/posts/Python-%E7%B6%B2%E9%A0%81%EF%BC%9Adjango-%E4%BE%86%E5%81%9A%E4%B8%80%E5%80%8B%E9%83%A8%E8%90%BD%E6%A0%BC1/"><meta property="og:see_also" content="https://jimmycode.tw/posts/Python%E7%B6%B2%E9%A0%81%E7%AF%87%EF%BC%9Adjango-%E7%B0%A1%E4%BB%8B/"><meta name=twitter:card content="summary"><meta name=twitter:title content="Python 走入現實：來爬蟲吧(2)"><meta name=twitter:description content="前一天我們談到如何使用Python發出類似瀏覽器的request，把所要的HTML+CSS+JS都給他抓過來。但是如果只是這樣那爬蟲又有什麼多厲害呢？ 爬蟲的厲害之處就是能把抓回來的東西，拿出來好好的分析，藉此獲得我們想要的資訊或者有用的資訊
因此，讓我接下來為他介紹收到request之後的事情吧！
BeautifulSoup 其實Python有許多的爬蟲套件，我之前個人下班在玩的時候都是用這個套件，當然也有其他可以爬的套件。這裏我介紹某位youtuber的資源：https://www.youtube.com/watch?v=T2xNeWutlcA
厲害吧！他居然用Python爬蟲去抓成人影片！呵呵 不過他用的是另外一種module 叫做pyquery
好啦，確定你有安裝好beautifulSoup之後就來開始吧這裡就不抓成人影片了，我們先開始抓取‘文字內容’，明天再來講我們怎麼抓取非文字內容的資料。我們來抓youtube今天熱門影片的標題們XD
大家都知道：youtube的熱門影片網址是：https://www.youtube.com/feed/trending
1import requests; 2from bs4 import BeautifulSoup; 3 4url=&#34;https://www.youtube.com/feed/trending/&#34; 5 6request=requests.get(url) 7content=request.content 8soup=BeautifulSoup(content,&#34;html.parser&#34;) 9 10container = soup.select(&#34;h3 a&#34;) 11 12# print(type(container)) 13# print(container) 14# 接下來只是寫入result.txt檔案的事情 15file = open('result.text','w') 16 17for item in container: 18 if item: 19 #print(type(item)) 20 value = item.get_text() 21 print(value) 22 file.write(value+'\n') 23 #break #這裡也提一個起手式的遺珠之憾，就是你可以用continue和break來處理 迴圈敘述，這裏為了我之前debug方便，使用break來讓我先只看一個的結果。 24 25 26file.close() 用範例講解：首先先把兩個module beautifulsoup ＆request引入接下來你會看到我使用request.get 取得熱門影片的youtube網頁的內容。再來你就用soup=BeautifulSoup(content,&#34;html.parser&#34;)把content 丟入beautifulSoup解析，後面參數記得加上‘html.parser’
然後回去用瀏覽器打開https://www.youtube.com/feed/trending/ 這個網頁，可能希望你會有一些基礎的html+css基礎，總之你可以仔細看看每個標題的地方，上面都會有h3 以及我們最想要的標題文字正好都被包在a這裡面。"><link rel=preload href=https://jimmycode.tw/css/bundle.min.f84a104bdb15a68121c670e3640c1943e6f0014b3007406dc2fd5090323e29f3.css integrity="sha256-+EoQS9sVpoEhxnDjZAwZQ+bwAUswB0Btwv1QkDI+KfM=" crossorigin=anonymous as=style onload="this.rel='stylesheet'"><noscript><link rel=stylesheet href=https://jimmycode.tw/css/bundle.min.f84a104bdb15a68121c670e3640c1943e6f0014b3007406dc2fd5090323e29f3.css integrity="sha256-+EoQS9sVpoEhxnDjZAwZQ+bwAUswB0Btwv1QkDI+KfM=" crossorigin=anonymous></noscript><script src=https://jimmycode.tw/js/bundle.min.ecfa3886c60f0ce241fc40aecfcbfe83c1172bc08bbcb04f9ac198491289716c.js integrity="sha256-7Po4hsYPDOJB/ECuz8v+g8EXK8CLvLBPmsGYSRKJcWw=" crossorigin=anonymous></script></head><body><script src=https://jimmycode.tw/js/bootstrap.min.b5d86dd3a5f60c90be38a252bb65fc1a2732f32e71dc12c051720f0c7aef3cde.js integrity="sha256-tdht06X2DJC+OKJSu2X8Gicy8y5x3BLAUXIPDHrvPN4=" crossorigin=anonymous></script><header><nav class="navbar top-app-bar top-app-bar-expand-lg"><div class=container-fluid><a class="navbar-brand me-3" href=https://jimmycode.tw/>Jimmy 's Code</a>
<button class=navbar-toggler type=button data-bs-toggle=collapse data-bs-target=#navbarSupportedContent aria-controls=navbarSupportedContent aria-expanded=false aria-label="Toggle navigation">
<i class="fas fa-ellipsis-v"></i></button><div class="collapse navbar-collapse" tabindex=-1 id=navbarSupportedContent aria-labelledby=navbarSupportedContent><form class="search-bar my-1" action=https://jimmycode.tw/search><div class="input-group input-group-sm"><span class="btn btn-search disabled position-absolute left-0"><i class="fas fa-fw fa-search"></i></span>
<input class="form-control rounded-pill" name=q type=search aria-label=Search></div></form><ul class="navbar-nav ms-auto"><li class=nav-item><a class=nav-link href=https://jimmycode.tw/archives><i class="fas fa-fw fa-file-archive"></i>歸檔</a></li><li class=nav-item><a class=nav-link href=https://jimmycode.tw/categories><i class="fas fa-fw fa-folder"></i>分類</a></li><li class=nav-item><a class=nav-link href=https://jimmycode.tw/tags><i class="fas fa-fw fa-tags"></i>標籤</a></li><li class=nav-item><a class=nav-link href=https://github.com/r567tw target=_blank rel="noopener noreferrer"><i class="fab fa-fw fa-github"></i>Github</a></li></ul></div></div></nav></header><main role=main class=container-fluid><div class="row content"><div class=col-lg-8><div class=container><nav class="row card component" aria-label=breadcrumb><div class=card-body><ol class=breadcrumb><li class=breadcrumb-item><a href=https://jimmycode.tw/>主頁</a></li><li class=breadcrumb-item><a href=https://jimmycode.tw/posts/>Posts</a></li><li class="breadcrumb-item active">Python 走入現實：來爬蟲吧(2)</li></ol></div></nav><article class="post row card mb-4 component"><div class=card-body><div class=post-panel-wrapper><div class="post-panel d-flex flex-column"><a id=sidebarToggler class="action d-none d-lg-block" role=button><i class="fas fa-fw fa-expand-arrows-alt"></i></a></div></div><h1 class="card-title my-3">Python 走入現實：來爬蟲吧(2)</h1><div class=post-meta><span class=post-date title="created on"><i class="fas fa-fw fa-calendar-alt"></i>Oct 17, 2018
</span><span class=post-reading-time title="reading time"><i class="fas fa-fw fa-coffee"></i>1 分鐘閱讀
</span><a href=https://jimmycode.tw/categories/%E9%90%B5%E4%BA%BA%E8%B3%BD/ class=post-taxonomy>鐵人賽</a><a href=https://jimmycode.tw/series/pythonx30/ class=post-taxonomy>PythonX30</a><a href=https://jimmycode.tw/tags/python/ class=post-taxonomy>python</a></div><div class="post-content mb-3"><p>前一天我們談到如何使用Python發出類似瀏覽器的request，把所要的HTML+CSS+JS都給他抓過來。但是如果只是這樣那爬蟲又有什麼多厲害呢？ 爬蟲的厲害之處就是能把抓回來的東西，拿出來好好的分析，<em><strong>藉此獲得我們想要的資訊或者有用的資訊</strong></em></p><p>因此，讓我接下來為他介紹收到request之後的事情吧！</p><h2 id=beautifulsoup>BeautifulSoup</h2><p>其實Python有許多的爬蟲套件，我之前個人下班在玩的時候都是用這個套件，當然也有其他可以爬的套件。這裏我介紹某位youtuber的資源：<a href="https://www.youtube.com/watch?v=T2xNeWutlcA">https://www.youtube.com/watch?v=T2xNeWutlcA</a></p><p>厲害吧！他居然用Python爬蟲去抓成人影片！呵呵 不過他用的是另外一種module 叫做pyquery</p><p>好啦，確定你有安裝好beautifulSoup之後就來開始吧這裡就不抓成人影片了，我們先開始抓取‘文字內容’，明天再來講我們怎麼抓取非文字內容的資料。我們來抓youtube今天熱門影片的標題們XD</p><p>大家都知道：youtube的熱門影片網址是：<a href=https://www.youtube.com/feed/trending>https://www.youtube.com/feed/trending</a></p><div class=highlight><pre class=chroma><code class=language-python data-lang=python><span class=ln> 1</span><span class=kn>import</span> <span class=nn>requests</span><span class=p>;</span>
<span class=ln> 2</span><span class=kn>from</span> <span class=nn>bs4</span> <span class=kn>import</span> <span class=n>BeautifulSoup</span><span class=p>;</span>
<span class=ln> 3</span>
<span class=ln> 4</span><span class=n>url</span><span class=o>=</span><span class=s2>&#34;https://www.youtube.com/feed/trending/&#34;</span>
<span class=ln> 5</span>
<span class=ln> 6</span><span class=n>request</span><span class=o>=</span><span class=n>requests</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=n>url</span><span class=p>)</span>
<span class=ln> 7</span><span class=n>content</span><span class=o>=</span><span class=n>request</span><span class=o>.</span><span class=n>content</span>
<span class=ln> 8</span><span class=n>soup</span><span class=o>=</span><span class=n>BeautifulSoup</span><span class=p>(</span><span class=n>content</span><span class=p>,</span><span class=s2>&#34;html.parser&#34;</span><span class=p>)</span>
<span class=ln> 9</span>
<span class=ln>10</span><span class=n>container</span> <span class=o>=</span> <span class=n>soup</span><span class=o>.</span><span class=n>select</span><span class=p>(</span><span class=s2>&#34;h3 a&#34;</span><span class=p>)</span>
<span class=ln>11</span>
<span class=ln>12</span><span class=c1># print(type(container))</span>
<span class=ln>13</span><span class=c1># print(container)</span>
<span class=ln>14</span><span class=c1># 接下來只是寫入result.txt檔案的事情</span>
<span class=ln>15</span><span class=n>file</span> <span class=o>=</span> <span class=nb>open</span><span class=p>(</span><span class=s1>&#39;result.text&#39;</span><span class=p>,</span><span class=s1>&#39;w&#39;</span><span class=p>)</span>
<span class=ln>16</span>
<span class=ln>17</span><span class=k>for</span> <span class=n>item</span> <span class=ow>in</span> <span class=n>container</span><span class=p>:</span>
<span class=ln>18</span>    <span class=k>if</span> <span class=n>item</span><span class=p>:</span>
<span class=ln>19</span>        <span class=c1>#print(type(item))</span>
<span class=ln>20</span>        <span class=n>value</span> <span class=o>=</span> <span class=n>item</span><span class=o>.</span><span class=n>get_text</span><span class=p>()</span>
<span class=ln>21</span>        <span class=nb>print</span><span class=p>(</span><span class=n>value</span><span class=p>)</span>
<span class=ln>22</span>        <span class=n>file</span><span class=o>.</span><span class=n>write</span><span class=p>(</span><span class=n>value</span><span class=o>+</span><span class=s1>&#39;</span><span class=se>\n</span><span class=s1>&#39;</span><span class=p>)</span>
<span class=ln>23</span>        <span class=c1>#break #這裡也提一個起手式的遺珠之憾，就是你可以用continue和break來處理 迴圈敘述，這裏為了我之前debug方便，使用break來讓我先只看一個的結果。</span>
<span class=ln>24</span>        
<span class=ln>25</span>
<span class=ln>26</span><span class=n>file</span><span class=o>.</span><span class=n>close</span><span class=p>()</span>
</code></pre></div><p>用範例講解：首先先把兩個module beautifulsoup ＆request引入接下來你會看到我使用request.get 取得熱門影片的youtube網頁的內容。再來你就用<code>soup=BeautifulSoup(content,"html.parser")</code>把content 丟入beautifulSoup解析，後面參數記得加上‘html.parser’</p><p>然後回去用瀏覽器打開<a href=https://www.youtube.com/feed/trending/>https://www.youtube.com/feed/trending/</a> 這個網頁，可能希望你會有一些基礎的html+css基礎，總之你可以仔細看看每個標題的地方，上面都會有h3 以及我們最想要的標題文字正好都被包在a這裡面。</p><p>所以我們可以使用<code>container = soup.select("h3 a")</code>來把所有的標題提出來。接下來只是寫入result.txt檔案的事情了</p><ol><li>你可以先<code>print(container)</code>和<code>print(type(container))</code> : 你會發現他是<code>&lt;class 'list'></code> ，所以你知道了吧！他就是個 list，所以後面我用迴圈把他一一提取出來。2.進入迴圈後如果你還是很好奇，可以用print(type(item))看看：他是<code>&lt;class 'bs4.element.Tag'></code>，所以後面我可以用get_text()這個方法取出他的標題文字。</li></ol><p>關於beautifulsoup還有很多可以在教學或更多運用的，這裏我附上我debug參考的一些網址</p><p>更多BeautifulSoup教學： <a href=https://www.dataquest.io/blog/web-scraping-tutorial-Python/>https://www.dataquest.io/blog/web-scraping-tutorial-Python/</a></p><p>明天我將試看看爬多媒體資源看看！敬請期待！</p></div><hr><div class="post-navs d-flex mb-3 justify-content-evenly"><div class="post-nav post-prev"><i class="fas fa-fw fa-chevron-left"></i>
<a href=https://jimmycode.tw/posts/Python-%E8%B5%B0%E5%85%A5%E7%8F%BE%E5%AF%A6%EF%BC%9A%E4%BE%86%E7%88%AC%E8%9F%B2%E5%90%A71/>Python 走入現實：來爬蟲吧(1)</a></div><div class="post-nav post-next"><a href=https://jimmycode.tw/posts/Python-%E8%B5%B0%E5%85%A5%E7%8F%BE%E5%AF%A6%EF%BC%9A%E6%AD%A3%E8%A6%8F%E8%A1%A8%E9%81%94%E5%BC%8F/>Python 走入現實：正規表達式</a>
<i class="fas fa-fw fa-chevron-right"></i></div></div></div></article><div class="post-comments card row component"><div class=card-body><script src=https://utteranc.es/client.js repo=r567tw/r567tw.github.io issue-term=title label=comment theme=github-light crossorigin=anonymous async></script></div></div></div></div><aside class="col-lg-4 sidebar d-flex"><div class=container><section class="card row text-center profile component"><div class=card-body><div class="col-12 d-flex align-items-center justify-content-center"><img class="profile-avatar rounded-circle" alt=r567tw src=http://gravatar.com/avatar/40ee6e5cf50763264e00578b83236bdf loading=lazy></div><div class="col-12 profile-meta"><div class=profile-name>r567tw</div><div class=profile-bio>Be a better Coder</div><div class=profile-company><i class="fas fa-fw fa-building"></i>UDN</div><div class=profile-location><i class="fas fa-fw fa-map-marker-alt"></i>Taiwan</div><div class=profile-about><i class="fas fa-fw fa-user"></i><a href=https://jimmycode.tw/about/>About</a></div></div></div></section><section class="recent-posts row card component"><div class=card-body><h2 class=card-title>最近文章</h2><ul><li><a href=https://jimmycode.tw/posts/go-%E5%AD%B8%E7%BF%92%E7%AD%86%E8%A8%986-%E5%AF%AB%E4%B8%80%E5%80%8B%E7%B6%B2%E9%A0%81%E5%90%A7%EF%BC%81/>Go 學習筆記(6): 寫一個網頁吧！</a></li><li><a href=https://jimmycode.tw/posts/%E5%8E%9F%E4%BE%86%E5%8F%AF%E4%BB%A5%E9%80%99%E9%BA%BC%E5%AF%AB13-%E5%85%B6%E5%AF%A6%E6%88%91%E6%9C%83%E4%B8%80%E9%BB%9E%E9%BB%9Eruby/>原來可以這麼寫(13): 其實我會一點點Ruby</a></li><li><a href=https://jimmycode.tw/posts/go-%E5%AD%B8%E7%BF%92%E7%AD%86%E8%A8%985-%E9%9D%9E%E5%90%8C%E6%AD%A5/>Go 學習筆記(5): 非同步</a></li><li><a href=https://jimmycode.tw/posts/go-%E5%AD%B8%E7%BF%92%E7%AD%86%E8%A8%984-%E6%AA%94%E6%A1%88/>Go 學習筆記(4) – 檔案</a></li><li><a href=https://jimmycode.tw/posts/go-%E5%AD%B8%E7%BF%92%E7%AD%86%E8%A8%983-%E5%81%9A%E5%A5%97%E4%BB%B6%E7%B5%A6%E5%88%A5%E4%BA%BA%E7%94%A8/>Go 學習筆記(3): 做套件給別人用</a></li></ul></div></section><section class="taxonomies row card component"><div class=card-body><h2 class=card-title><a href=https://jimmycode.tw/categories>分類</a></h2><div><a href=https://jimmycode.tw/categories/%E9%90%B5%E4%BA%BA%E8%B3%BD/ class="post-taxonomy rounded btn btn-sm btn-outline-primary me-2 mb-2" title=鐵人賽>鐵人賽
</a><a href=https://jimmycode.tw/categories/%E7%A8%8B%E5%BC%8F/ class="post-taxonomy rounded btn btn-sm btn-outline-primary me-2 mb-2" title=程式>程式
</a><a href=https://jimmycode.tw/categories/%E5%B7%A5%E4%BD%9C%E7%AD%86%E8%A8%98/ class="post-taxonomy rounded btn btn-sm btn-outline-primary me-2 mb-2" title=工作筆記>工作筆記
</a><a href=https://jimmycode.tw/categories/%E8%AE%80%E6%9B%B8%E7%AD%86%E8%A8%98/ class="post-taxonomy rounded btn btn-sm btn-outline-primary me-2 mb-2" title=讀書筆記>讀書筆記
</a><a href=https://jimmycode.tw/categories/%E8%AE%80%E6%9B%B8%E5%BF%83%E5%BE%97/ class="post-taxonomy rounded btn btn-sm btn-outline-primary me-2 mb-2" title=讀書心得>讀書心得
</a><a href=https://jimmycode.tw/categories/%E4%BF%A1%E4%BB%B0/ class="post-taxonomy rounded btn btn-sm btn-outline-primary me-2 mb-2" title=信仰>信仰
</a><a href=https://jimmycode.tw/categories/%E6%97%85%E8%A1%8C/ class="post-taxonomy rounded btn btn-sm btn-outline-primary me-2 mb-2" title=旅行>旅行
</a><a href=https://jimmycode.tw/categories/side-projects/ class="post-taxonomy rounded btn btn-sm btn-outline-primary me-2 mb-2" title="Side Projects">Side Projects</a></div></div></section><section class="taxonomies row card component"><div class=card-body><h2 class=card-title><a href=https://jimmycode.tw/series>專欄</a></h2><div><a href=https://jimmycode.tw/series/pythonx30/ class="post-taxonomy rounded btn btn-sm btn-outline-primary me-2 mb-2" title=PythonX30>PythonX30
</a><a href=https://jimmycode.tw/series/%E8%AE%93php%E5%86%8D%E6%AC%A1%E5%81%89%E5%A4%A7/ class="post-taxonomy rounded btn btn-sm btn-outline-primary me-2 mb-2" title=讓PHP再次偉大>讓PHP再次偉大
</a><a href=https://jimmycode.tw/series/%E5%8E%9F%E4%BE%86%E5%8F%AF%E4%BB%A5%E9%80%99%E9%BA%BC%E5%AF%AB/ class="post-taxonomy rounded btn btn-sm btn-outline-primary me-2 mb-2" title=原來可以這麼寫>原來可以這麼寫
</a><a href=https://jimmycode.tw/series/go-%E5%AD%B8%E7%BF%92%E7%AD%86%E8%A8%98/ class="post-taxonomy rounded btn btn-sm btn-outline-primary me-2 mb-2" title="go 學習筆記">go 學習筆記</a></div></div></section><section class="taxonomies row card component"><div class=card-body><h2 class=card-title><a href=https://jimmycode.tw/tags>標籤</a></h2><div><a href=https://jimmycode.tw/tags/laravel/ class="post-taxonomy rounded btn btn-sm btn-outline-primary me-2 mb-2" title=laravel>laravel
</a><a href=https://jimmycode.tw/tags/python/ class="post-taxonomy rounded btn btn-sm btn-outline-primary me-2 mb-2" title=python>python
</a><a href=https://jimmycode.tw/tags/golang/ class="post-taxonomy rounded btn btn-sm btn-outline-primary me-2 mb-2" title=golang>golang
</a><a href=https://jimmycode.tw/tags/mysql/ class="post-taxonomy rounded btn btn-sm btn-outline-primary me-2 mb-2" title=mysql>mysql
</a><a href=https://jimmycode.tw/tags/aws/ class="post-taxonomy rounded btn btn-sm btn-outline-primary me-2 mb-2" title=aws>aws
</a><a href=https://jimmycode.tw/tags/php/ class="post-taxonomy rounded btn btn-sm btn-outline-primary me-2 mb-2" title=php>php
</a><a href=https://jimmycode.tw/tags/composer/ class="post-taxonomy rounded btn btn-sm btn-outline-primary me-2 mb-2" title=composer>composer
</a><a href=https://jimmycode.tw/tags/crud/ class="post-taxonomy rounded btn btn-sm btn-outline-primary me-2 mb-2" title=crud>crud
</a><a href=https://jimmycode.tw/tags/lambda/ class="post-taxonomy rounded btn btn-sm btn-outline-primary me-2 mb-2" title=lambda>lambda
</a><a href=https://jimmycode.tw/tags/ruby/ class="post-taxonomy rounded btn btn-sm btn-outline-primary me-2 mb-2" title=ruby>ruby
</a><a href=https://jimmycode.tw/tags/async/ class="post-taxonomy rounded btn btn-sm btn-outline-primary me-2 mb-2" title=async>async
</a><a href=https://jimmycode.tw/tags/aws-step-function/ class="post-taxonomy rounded btn btn-sm btn-outline-primary me-2 mb-2" title=aws-step-function>aws-step-function
</a><a href=https://jimmycode.tw/tags/c%E5%9E%8B%E8%A7%80%E9%BB%9E/ class="post-taxonomy rounded btn btn-sm btn-outline-primary me-2 mb-2" title=C型觀點>C型觀點
</a><a href=https://jimmycode.tw/tags/data-import/ class="post-taxonomy rounded btn btn-sm btn-outline-primary me-2 mb-2" title=data-import>data-import
</a><a href=https://jimmycode.tw/tags/devops/ class="post-taxonomy rounded btn btn-sm btn-outline-primary me-2 mb-2" title=DevOps>DevOps</a></div></div></section></div></aside></div></main><footer class="footer mt-auto py-3 text-center container-fluid"><div class="copyright mb-2">Copyright © 2022-2021 Jimmy Fang. All Rights Reserved.</div></footer><script type=application/javascript>var doNotTrack=!1;doNotTrack||(window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)},ga.l=+new Date,ga('create','UA-211893638-1','auto'),ga('send','pageview'))</script><script async src=https://www.google-analytics.com/analytics.js></script></body></html>